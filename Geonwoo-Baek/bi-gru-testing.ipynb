{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f30ed0c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-11T07:38:25.176140Z",
     "iopub.status.busy": "2023-12-11T07:38:25.175709Z",
     "iopub.status.idle": "2023-12-11T07:38:25.887574Z",
     "shell.execute_reply": "2023-12-11T07:38:25.886649Z"
    },
    "papermill": {
     "duration": 0.720245,
     "end_time": "2023-12-11T07:38:25.889705",
     "exception": false,
     "start_time": "2023-12-11T07:38:25.169460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/child-mind-institute-detect-sleep-states/train_series.parquet\n",
      "/kaggle/input/child-mind-institute-detect-sleep-states/sample_submission.csv\n",
      "/kaggle/input/child-mind-institute-detect-sleep-states/train_events.csv\n",
      "/kaggle/input/child-mind-institute-detect-sleep-states/test_series.parquet\n",
      "/kaggle/input/model-gru/model_best.pth\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32915ee1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T07:38:25.899421Z",
     "iopub.status.busy": "2023-12-11T07:38:25.899021Z",
     "iopub.status.idle": "2023-12-11T07:38:30.382107Z",
     "shell.execute_reply": "2023-12-11T07:38:30.381150Z"
    },
    "papermill": {
     "duration": 4.490135,
     "end_time": "2023-12-11T07:38:30.384229",
     "exception": false,
     "start_time": "2023-12-11T07:38:25.894094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from functools import wraps\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import gc\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "torch.set_num_interop_threads(4)\n",
    "torch.set_num_threads(4)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49682eb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T07:38:30.394508Z",
     "iopub.status.busy": "2023-12-11T07:38:30.394088Z",
     "iopub.status.idle": "2023-12-11T07:38:30.399340Z",
     "shell.execute_reply": "2023-12-11T07:38:30.398565Z"
    },
    "papermill": {
     "duration": 0.012497,
     "end_time": "2023-12-11T07:38:30.401194",
     "exception": false,
     "start_time": "2023-12-11T07:38:30.388697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def track_time(f):\n",
    "    @wraps(f)\n",
    "    def wrap(*args, **kw):\n",
    "        ts = time.time()\n",
    "        result = f(*args, **kw)\n",
    "        te = time.time()\n",
    "        print('func:%r took: %2.4f sec' % \\\n",
    "          (f.__name__, te-ts))\n",
    "        return result\n",
    "    return wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b448b73f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T07:38:30.411194Z",
     "iopub.status.busy": "2023-12-11T07:38:30.410701Z",
     "iopub.status.idle": "2023-12-11T07:38:30.421486Z",
     "shell.execute_reply": "2023-12-11T07:38:30.420793Z"
    },
    "papermill": {
     "duration": 0.017674,
     "end_time": "2023-12-11T07:38:30.423343",
     "exception": false,
     "start_time": "2023-12-11T07:38:30.405669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "columns_to_scale = ['anglez', 'enmo']\n",
    "class DataParser:\n",
    "    def __init__(self, data_dir: str = \"/kaggle/input/child-mind-institute-detect-sleep-states\") -> None:\n",
    "        self.data_dir = data_dir\n",
    "\n",
    "    @track_time\n",
    "    def _clean(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        if \"step\" in df.columns and \"timestamp\" in df.columns:\n",
    "            df = df.dropna(subset=[\"step\", \"timestamp\"])\n",
    "            return df\n",
    "        else:\n",
    "            raise KeyError(\"Missing columns: either `step` or `timestamp` not exist.\")\n",
    "\n",
    "    @track_time\n",
    "    def _transform(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        if \"night\" in df.columns:\n",
    "            df[\"night\"] = df[\"night\"].astype(np.int16)\n",
    "\n",
    "        if \"step\" in df.columns and \"timestamp\" in df.columns:\n",
    "            df[\"step\"] = df[\"step\"].astype(np.int32)\n",
    "            df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], format=\"%Y-%m-%dT%H:%M:%S%z\", utc=True)\n",
    "\n",
    "        if \"anglez\" and \"enmo\" in df.columns:\n",
    "            normalized_data = scaler.fit_transform(df[columns_to_scale])\n",
    "            df['anglez_norm'] = normalized_data[:, 0]\n",
    "            df['enmo_norm'] = normalized_data[:, 1]\n",
    "            \n",
    "        df['hour'] = df['timestamp'].dt.hour\n",
    "\n",
    "        return df\n",
    "\n",
    "    def load_data(self, file_name: str, file_type: str) -> pd.DataFrame:\n",
    "        if file_type == \"parquet\":\n",
    "            df = pd.read_parquet(os.path.join(self.data_dir, file_name))\n",
    "            df = self._clean(df)\n",
    "            df = self._transform(df)\n",
    "        else:\n",
    "            df = pd.read_csv(os.path.join(self.data_dir, file_name))\n",
    "            df = self._clean(df)\n",
    "            \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04d26d43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T07:38:30.432570Z",
     "iopub.status.busy": "2023-12-11T07:38:30.432286Z",
     "iopub.status.idle": "2023-12-11T07:38:30.664712Z",
     "shell.execute_reply": "2023-12-11T07:38:30.663733Z"
    },
    "papermill": {
     "duration": 0.240135,
     "end_time": "2023-12-11T07:38:30.667592",
     "exception": false,
     "start_time": "2023-12-11T07:38:30.427457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "func:'_clean' took: 0.0035 sec\n",
      "func:'_transform' took: 0.0181 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = DataParser()\n",
    "test_series = parser.load_data(\"test_series.parquet\", \"parquet\")\n",
    "ids = test_series.series_id.unique()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "735ea975",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T07:38:30.678063Z",
     "iopub.status.busy": "2023-12-11T07:38:30.677799Z",
     "iopub.status.idle": "2023-12-11T07:38:30.694083Z",
     "shell.execute_reply": "2023-12-11T07:38:30.693248Z"
    },
    "papermill": {
     "duration": 0.023922,
     "end_time": "2023-12-11T07:38:30.696196",
     "exception": false,
     "start_time": "2023-12-11T07:38:30.672274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResidualBiGRU(nn.Module):\n",
    "    def __init__(self, hidden_size, n_layers=1, bidir=True):\n",
    "        super(ResidualBiGRU, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            hidden_size,\n",
    "            hidden_size,\n",
    "            n_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidir,\n",
    "        )\n",
    "        dir_factor = 2 if bidir else 1\n",
    "        self.fc1 = nn.Linear(\n",
    "            hidden_size * dir_factor, hidden_size * dir_factor * 2\n",
    "        )\n",
    "        self.ln1 = nn.LayerNorm(hidden_size * dir_factor * 2)\n",
    "        self.fc2 = nn.Linear(hidden_size * dir_factor * 2, hidden_size)\n",
    "        self.ln2 = nn.LayerNorm(hidden_size)\n",
    "\n",
    "    def forward(self, x, h=None):\n",
    "        res, new_h = self.gru(x, h)\n",
    "\n",
    "        res = self.fc1(res)\n",
    "        res = self.ln1(res)\n",
    "        res = nn.functional.relu(res)\n",
    "        \n",
    "        res = self.fc2(res)\n",
    "        res = self.ln2(res)\n",
    "        res = nn.functional.relu(res)\n",
    "        \n",
    "        res = res + x\n",
    "\n",
    "        return res, new_h\n",
    "\n",
    "class MultiResidualBiGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, out_size, n_layers, kernel_size=3, bidir=True):\n",
    "        super(MultiResidualBiGRU, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.out_size = out_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.conv1d = nn.Conv1d(in_channels=input_size, out_channels=(hidden_size - input_size) // 2, kernel_size=kernel_size, padding=kernel_size // 2)\n",
    "        self.conv_gn = nn.GroupNorm(1, (hidden_size - input_size) // 2)\n",
    "\n",
    "        self.conv1d_5 = nn.Conv1d(in_channels=input_size, out_channels=(hidden_size - input_size) // 2, kernel_size=5, padding=2)\n",
    "        self.conv1d_gn_5 = nn.GroupNorm(1, (hidden_size - input_size) // 2)\n",
    "\n",
    "        self.res_bigrus = nn.ModuleList([\n",
    "            ResidualBiGRU(hidden_size, n_layers=1, bidir=bidir) for _ in range(n_layers)\n",
    "        ])\n",
    "        \n",
    "        self.fc_out = nn.Linear(hidden_size, out_size)\n",
    "\n",
    "    def forward(self, x, h=None):\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "        x1 = self.conv1d(x)\n",
    "        x1 = self.conv_gn(x1)\n",
    "        x1 = nn.functional.relu(x1)\n",
    "\n",
    "        x2 = self.conv1d_5(x)\n",
    "        x2 = self.conv1d_gn_5(x2)\n",
    "        x2 = nn.functional.relu(x2)\n",
    "        \n",
    "        x = torch.cat((x, x1, x2), dim=1)\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "        if h is None:\n",
    "            h = [None for _ in range(self.n_layers)]\n",
    "\n",
    "        new_h = []\n",
    "        for i, res_bigru in enumerate(self.res_bigrus):\n",
    "            x, new_hi = res_bigru(x, h[i])\n",
    "            new_h.append(new_hi)\n",
    "\n",
    "        x = self.fc_out(x)\n",
    "        return x, new_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb3c0544",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T07:38:30.707237Z",
     "iopub.status.busy": "2023-12-11T07:38:30.706975Z",
     "iopub.status.idle": "2023-12-11T07:38:30.836181Z",
     "shell.execute_reply": "2023-12-11T07:38:30.835260Z"
    },
    "papermill": {
     "duration": 0.139181,
     "end_time": "2023-12-11T07:38:30.839969",
     "exception": false,
     "start_time": "2023-12-11T07:38:30.700788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "175dc095449a46e788f116cab7a8c7ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAMPLE_FREQ = 12\n",
    "class SleepDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        series_ids,\n",
    "        series,\n",
    "    ):\n",
    "        series_ids = series_ids\n",
    "        series = series.reset_index()\n",
    "        self.data = []\n",
    "        \n",
    "        for viz_id in tqdm(series_ids):\n",
    "            self.data.append(series.loc[(series.series_id==viz_id)].copy().reset_index())\n",
    "            \n",
    "    def downsample_seq_generate_features(self, feat, downsample_factor=SAMPLE_FREQ, std_only=False, is_hour=False):\n",
    "        if len(feat) % downsample_factor != 0:\n",
    "            feat = np.concatenate([feat, np.zeros(downsample_factor-((len(feat))%downsample_factor))+feat[-1]])\n",
    "\n",
    "        feat = np.reshape(feat, (-1, downsample_factor))\n",
    "        \n",
    "        if is_hour:\n",
    "            feat_hour = np.max(feat, 1)\n",
    "            hour_sin = np.sin(feat_hour * (2 * np.pi / 24))\n",
    "            hour_cos = np.cos(feat_hour * (2 * np.pi / 24))\n",
    "            return np.dstack([hour_sin, hour_cos])[0]\n",
    "\n",
    "        feat_mean   = np.mean(feat,1)\n",
    "        feat_std    = np.std(feat,1)\n",
    "        feat_median = np.median(feat,1)\n",
    "        feat_max    = np.max(feat,1)\n",
    "        feat_min    = np.min(feat,1)\n",
    "\n",
    "        if std_only:\n",
    "            return np.dstack([feat_std])[0]\n",
    "    \n",
    "        return np.dstack([feat_mean, feat_std, feat_median, feat_max, feat_min])[0]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = self.data[index][[\"anglez_norm\", \"enmo_norm\", \"hour\"]]\n",
    "        \n",
    "        X_anglez = self.downsample_seq_generate_features(X.values[:, 0], SAMPLE_FREQ, std_only=True)\n",
    "        X_enmo   = self.downsample_seq_generate_features(X.values[:, 1], SAMPLE_FREQ)\n",
    "        X_hour   = self.downsample_seq_generate_features(X.values[:, 2], SAMPLE_FREQ, is_hour=True)\n",
    "        \n",
    "        X = np.concatenate([X_anglez, X_enmo, X_hour], -1)\n",
    "        X = torch.from_numpy(X)\n",
    "        return X\n",
    "    \n",
    "test_ds = SleepDataset(test_series.series_id.unique(),test_series)\n",
    "del test_series\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46161831",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T07:38:30.851288Z",
     "iopub.status.busy": "2023-12-11T07:38:30.850981Z",
     "iopub.status.idle": "2023-12-11T07:38:30.855260Z",
     "shell.execute_reply": "2023-12-11T07:38:30.854395Z"
    },
    "papermill": {
     "duration": 0.012093,
     "end_time": "2023-12-11T07:38:30.857148",
     "exception": false,
     "start_time": "2023-12-11T07:38:30.845055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_chunk_size = 24*60*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a94a8e9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T07:38:30.868392Z",
     "iopub.status.busy": "2023-12-11T07:38:30.868080Z",
     "iopub.status.idle": "2023-12-11T07:38:30.873975Z",
     "shell.execute_reply": "2023-12-11T07:38:30.873097Z"
    },
    "papermill": {
     "duration": 0.013832,
     "end_time": "2023-12-11T07:38:30.875977",
     "exception": false,
     "start_time": "2023-12-11T07:38:30.862145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_close_candidates(onset_candidates, wakeup_candidates, min_interval=30):\n",
    "    filtered_onset = []\n",
    "    filtered_wakeup = []\n",
    "\n",
    "    onset_set = set(onset_candidates)\n",
    "    wakeup_set = set(wakeup_candidates)\n",
    "\n",
    "    for onset in onset_candidates:\n",
    "        if all(abs(onset - wakeup) >= min_interval for wakeup in wakeup_set):\n",
    "            filtered_onset.append(onset)\n",
    "\n",
    "    for wakeup in wakeup_candidates:\n",
    "        if all(abs(wakeup - onset) >= min_interval for onset in onset_set):\n",
    "            filtered_wakeup.append(wakeup)\n",
    "\n",
    "    return filtered_onset, filtered_wakeup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddb0fe22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T07:38:30.887607Z",
     "iopub.status.busy": "2023-12-11T07:38:30.886940Z",
     "iopub.status.idle": "2023-12-11T07:38:39.339408Z",
     "shell.execute_reply": "2023-12-11T07:38:39.338310Z"
    },
    "papermill": {
     "duration": 8.460832,
     "end_time": "2023-12-11T07:38:39.341814",
     "exception": false,
     "start_time": "2023-12-11T07:38:30.880982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = MultiResidualBiGRU(input_size=8, hidden_size=64, out_size=2, n_layers=5).to(device)\n",
    "model.load_state_dict(torch.load(f'/kaggle/input/model-gru/gru-model_best.pth',map_location=device))\n",
    "submission = pd.DataFrame()\n",
    "for i in range(len(test_ds)):\n",
    "    X = test_ds[i].unsqueeze(0)\n",
    "    seq_len = X.shape[1]\n",
    "    X = X.to(device)\n",
    "    h = None\n",
    "    pred = torch.zeros((seq_len, 2)).half()\n",
    "    \n",
    "    for j in range(0, seq_len, max_chunk_size):\n",
    "        y_pred, h = model(X[:, j: j + max_chunk_size, :].float(), h)\n",
    "        h = [hi.detach() for hi in h]\n",
    "        pred[j: j + max_chunk_size] = y_pred.detach()\n",
    "        del y_pred; gc.collect()\n",
    "\n",
    "    pred = pred.cpu().numpy()\n",
    "    series_id = ids[i]\n",
    "\n",
    "    days = len(pred) / (17280 / SAMPLE_FREQ)\n",
    "    scores0, scores1 = np.zeros(len(pred), dtype=np.float16), np.zeros(len(pred), dtype=np.float16)\n",
    "    \n",
    "    for min_interval in [30]:\n",
    "        for index in range(len(pred)):\n",
    "            if pred[index, 0] == max(pred[max(0, index - min_interval): index + min_interval, 0]):\n",
    "                scores0[index] = max(pred[max(0, index - min_interval): index + min_interval, 0])\n",
    "            if pred[index, 1] == max(pred[max(0, index - min_interval): index + min_interval, 1]):\n",
    "                scores1[index] = max(pred[max(0, index - min_interval): index + min_interval, 1])\n",
    "\n",
    "    candidates_onset = np.argsort(scores0)[-max(1, round(days)):]\n",
    "    candidates_wakeup = np.argsort(scores1)[-max(1, round(days)):]\n",
    "\n",
    "    candidates_onset, candidates_wakeup = filter_close_candidates(candidates_onset, candidates_wakeup, min_interval=30)\n",
    "\n",
    "    onset = test_ds.data[i][['step']].iloc[np.clip(candidates_onset * SAMPLE_FREQ, 0, len(test_ds.data[i]) - 1)].astype(np.int32)\n",
    "    onset['event'] = 'onset'\n",
    "    onset['series_id'] = series_id\n",
    "    onset['score'] = scores0[candidates_onset]\n",
    "\n",
    "    wakeup = test_ds.data[i][['step']].iloc[np.clip(candidates_wakeup * SAMPLE_FREQ, 0, len(test_ds.data[i]) - 1)].astype(np.int32)\n",
    "    wakeup['event'] = 'wakeup'\n",
    "    wakeup['series_id'] = series_id\n",
    "    wakeup['score'] = scores1[candidates_wakeup]\n",
    "\n",
    "    submission = pd.concat([submission, onset, wakeup], axis=0)\n",
    "    del onset, wakeup, candidates_onset, candidates_wakeup, scores0, scores1, pred, series_id\n",
    "    gc.collect()\n",
    "\n",
    "submission = submission.sort_values(['series_id', 'step']).reset_index(drop=True)\n",
    "submission['row_id'] = submission.index.astype(int)\n",
    "submission['score'] = submission['score'].fillna(submission['score'].mean())\n",
    "submission = submission[['row_id', 'series_id', 'step', 'event', 'score']]\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cc155ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T07:38:39.353971Z",
     "iopub.status.busy": "2023-12-11T07:38:39.353259Z",
     "iopub.status.idle": "2023-12-11T07:38:39.363573Z",
     "shell.execute_reply": "2023-12-11T07:38:39.362720Z"
    },
    "papermill": {
     "duration": 0.018139,
     "end_time": "2023-12-11T07:38:39.365589",
     "exception": false,
     "start_time": "2023-12-11T07:38:39.347450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>step</th>\n",
       "      <th>event</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [row_id, series_id, step, event, score]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 6589269,
     "sourceId": 53666,
     "sourceType": "competition"
    },
    {
     "datasetId": 4134430,
     "sourceId": 7158654,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30616,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19.13092,
   "end_time": "2023-12-11T07:38:40.891538",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-11T07:38:21.760618",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "12647dadf7c04067b8b1cdcea13e5f6c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "175dc095449a46e788f116cab7a8c7ac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_aaf5c6dd03544f03957463f6b694b8a4",
        "IPY_MODEL_e7798fa18c38483694f965053d83be55",
        "IPY_MODEL_9d2e80b78f4046cea68842460910bbc3"
       ],
       "layout": "IPY_MODEL_4f265d93ac8b4e5388fea69e58dae257"
      }
     },
     "1d97ccd26b494cb4b6f8d6d794700299": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4f265d93ac8b4e5388fea69e58dae257": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9d2e80b78f4046cea68842460910bbc3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a0de6dff4ea348bb86a869285d0823e9",
       "placeholder": "​",
       "style": "IPY_MODEL_12647dadf7c04067b8b1cdcea13e5f6c",
       "value": " 3/3 [00:00&lt;00:00, 159.60it/s]"
      }
     },
     "9f76079f23e5431ea02534d91568c59b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a0de6dff4ea348bb86a869285d0823e9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "aaf5c6dd03544f03957463f6b694b8a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9f76079f23e5431ea02534d91568c59b",
       "placeholder": "​",
       "style": "IPY_MODEL_1d97ccd26b494cb4b6f8d6d794700299",
       "value": "100%"
      }
     },
     "c8da39a795ac4327b00e7eb8c130a7d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e7798fa18c38483694f965053d83be55": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_eee3c31f9c1b4ba4836acb027fa13e94",
       "max": 3,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c8da39a795ac4327b00e7eb8c130a7d2",
       "value": 3
      }
     },
     "eee3c31f9c1b4ba4836acb027fa13e94": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
