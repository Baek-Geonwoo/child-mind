{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baf11ee6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T23:33:50.438691Z",
     "iopub.status.busy": "2023-12-05T23:33:50.438291Z",
     "iopub.status.idle": "2023-12-05T23:33:51.193916Z",
     "shell.execute_reply": "2023-12-05T23:33:51.192936Z"
    },
    "papermill": {
     "duration": 0.7652,
     "end_time": "2023-12-05T23:33:51.196432",
     "exception": false,
     "start_time": "2023-12-05T23:33:50.431232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/testmodel/transformer_epoch_1.pth\n",
      "/kaggle/input/testmodel/model_best.pth\n",
      "/kaggle/input/testmodel/model_train_1.pth\n",
      "/kaggle/input/testmodel/model_valid_5.pth\n",
      "/kaggle/input/child-mind-institute-detect-sleep-states/train_series.parquet\n",
      "/kaggle/input/child-mind-institute-detect-sleep-states/sample_submission.csv\n",
      "/kaggle/input/child-mind-institute-detect-sleep-states/train_events.csv\n",
      "/kaggle/input/child-mind-institute-detect-sleep-states/test_series.parquet\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b231fbe0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T23:33:51.205522Z",
     "iopub.status.busy": "2023-12-05T23:33:51.205087Z",
     "iopub.status.idle": "2023-12-05T23:33:57.680280Z",
     "shell.execute_reply": "2023-12-05T23:33:57.679394Z"
    },
    "papermill": {
     "duration": 6.48227,
     "end_time": "2023-12-05T23:33:57.682662",
     "exception": false,
     "start_time": "2023-12-05T23:33:51.200392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from pyarrow.parquet import ParquetFile\n",
    "import pyarrow as pa\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d5f0240",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T23:33:57.692880Z",
     "iopub.status.busy": "2023-12-05T23:33:57.692548Z",
     "iopub.status.idle": "2023-12-05T23:33:57.714903Z",
     "shell.execute_reply": "2023-12-05T23:33:57.713871Z"
    },
    "papermill": {
     "duration": 0.030258,
     "end_time": "2023-12-05T23:33:57.717123",
     "exception": false,
     "start_time": "2023-12-05T23:33:57.686865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PATHS:\n",
    "    MAIN_DIR = \"/kaggle/input/child-mind-institute-detect-sleep-states/\"\n",
    "    SUBMISSION = MAIN_DIR + \"sample_submission.csv\"\n",
    "    TRAIN_EVENTS = MAIN_DIR + \"train_events.csv\"\n",
    "    TRAIN_SERIES = MAIN_DIR + \"train_series.parquet\"\n",
    "    TEST_SERIES = MAIN_DIR + \"test_series.parquet\"\n",
    "class CFG:\n",
    "    DEMO_MODE = True\n",
    "class data_reader:\n",
    "    def __init__(self, demo_mode):\n",
    "        super().__init__()\n",
    "        self.names_mapping = {\n",
    "            \"submission\" : {\"path\" : PATHS.SUBMISSION, \"is_parquet\" : False, \"has_timestamp\" : False}, \n",
    "            \"train_events\" : {\"path\" : PATHS.TRAIN_EVENTS, \"is_parquet\" : False, \"has_timestamp\" : True},\n",
    "            \"train_series\" : {\"path\" : PATHS.TRAIN_SERIES, \"is_parquet\" : True, \"has_timestamp\" : True},\n",
    "            \"test_series\" : {\"path\" : PATHS.TEST_SERIES, \"is_parquet\" : True, \"has_timestamp\" : True}\n",
    "        }\n",
    "        self.valid_names = [\"submission\", \"train_events\", \"train_series\", \"test_series\"]\n",
    "        self.demo_mode = demo_mode\n",
    "    \n",
    "    def verify(self, data_name):\n",
    "        \"function for data name verification\"\n",
    "        if data_name not in self.valid_names:\n",
    "            print(\"PLEASE ENTER A VALID DATASET NAME, VALID NAMES ARE : \", self.valid_names)\n",
    "        return\n",
    "    \n",
    "    def cleaning(self, data):\n",
    "        \"cleaning function : drop na values\"\n",
    "        data = data.dropna(subset=[\"timestamp\"])\n",
    "        return data\n",
    "    \n",
    "    @staticmethod\n",
    "    def reduce_memory_usage(data):\n",
    "        \"iterate through all the columns of a dataframe and modify the data type to reduce memory usage.\"\n",
    "        for col in data.columns:\n",
    "            col_type = data[col].dtype    \n",
    "            if col_type != object:\n",
    "                c_min = data[col].min()\n",
    "                c_max = data[col].max()\n",
    "                if str(col_type)[:3] == 'int':\n",
    "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                        data[col] = data[col].astype(np.int8)\n",
    "                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                        data[col] = data[col].astype(np.int16)\n",
    "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                        data[col] = data[col].astype(np.int32)\n",
    "                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                        data[col] = data[col].astype(np.int64)  \n",
    "                else:\n",
    "                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                        data[col] = data[col].astype(np.float16)\n",
    "                    elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                        data[col] = data[col].astype(np.float32)\n",
    "                    else:\n",
    "                        data[col] = data[col].astype(np.float64)\n",
    "            else:\n",
    "                data[col] = data[col].astype('category')\n",
    "\n",
    "        return data\n",
    "    \n",
    "    def load_data(self, data_name):\n",
    "        \"function for data loading\"\n",
    "        self.verify(data_name)\n",
    "        data_props = self.names_mapping[data_name]\n",
    "        if data_props[\"is_parquet\"]:\n",
    "            if self.demo_mode:\n",
    "                pf = ParquetFile(data_props[\"path\"]) \n",
    "                demo_rows = next(pf.iter_batches(batch_size=20_000)) \n",
    "                data = pa.Table.from_batches([demo_rows]).to_pandas()\n",
    "            else:\n",
    "                data = pd.read_parquet(data_props[\"path\"])\n",
    "        else:\n",
    "            if self.demo_mode:\n",
    "                data = pd.read_csv(data_props[\"path\"], nrows=20_000)\n",
    "            else:\n",
    "                data = pd.read_csv(data_props[\"path\"])\n",
    "                \n",
    "        gc.collect()\n",
    "        if data_props[\"has_timestamp\"]:\n",
    "            data = self.cleaning(data)\n",
    "            gc.collect()\n",
    "        data = self.reduce_memory_usage(data)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96b3de0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T23:33:57.726218Z",
     "iopub.status.busy": "2023-12-05T23:33:57.725887Z",
     "iopub.status.idle": "2023-12-05T23:33:58.124683Z",
     "shell.execute_reply": "2023-12-05T23:33:58.123865Z"
    },
    "papermill": {
     "duration": 0.406228,
     "end_time": "2023-12-05T23:33:58.127418",
     "exception": false,
     "start_time": "2023-12-05T23:33:57.721190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "reader = data_reader(demo_mode=False)\n",
    "test_series = reader.load_data(data_name=\"test_series\")\n",
    "ids = test_series.series_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80dcd09a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T23:33:58.136963Z",
     "iopub.status.busy": "2023-12-05T23:33:58.136345Z",
     "iopub.status.idle": "2023-12-05T23:33:58.148965Z",
     "shell.execute_reply": "2023-12-05T23:33:58.147911Z"
    },
    "papermill": {
     "duration": 0.019208,
     "end_time": "2023-12-05T23:33:58.150869",
     "exception": false,
     "start_time": "2023-12-05T23:33:58.131661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.3, max_len=24*60):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, out_size, n_layers):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.out_size = out_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.fc_in = nn.Linear(input_size, hidden_size)\n",
    "        self.ln = nn.LayerNorm(hidden_size)\n",
    "        \n",
    "        encoder_layers = nn.TransformerEncoderLayer(hidden_size, 2)\n",
    "        encoder_layers.self_attn.batch_first = True\n",
    "        \n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, n_layers)\n",
    "        \n",
    "        self.fc_out = nn.Linear(hidden_size, out_size)\n",
    "        self.pos_encoder = PositionalEncoding(hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc_in(x)\n",
    "        x = self.ln(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = self.fc_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "501d4831",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T23:33:58.159965Z",
     "iopub.status.busy": "2023-12-05T23:33:58.159168Z",
     "iopub.status.idle": "2023-12-05T23:33:58.170870Z",
     "shell.execute_reply": "2023-12-05T23:33:58.169853Z"
    },
    "papermill": {
     "duration": 0.018343,
     "end_time": "2023-12-05T23:33:58.172847",
     "exception": false,
     "start_time": "2023-12-05T23:33:58.154504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SleepDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, series_id\n",
    "    ):\n",
    "        self.data = series_id\n",
    "    def downsample_seq_generate_features(self, feat, target, downsample_factor = 12):\n",
    "        if target == 0: #angelz만 적용\n",
    "            feat = np.diff(feat)\n",
    "            feat = np.insert(feat, 0, feat[0])\n",
    "            feat = np.abs(feat) #크기를 적용\n",
    "        if len(feat)%downsample_factor!=0:\n",
    "            feat = np.concatenate([feat,np.zeros(downsample_factor-((len(feat))%downsample_factor))+feat[-1]])\n",
    "        feat = np.reshape(feat, (-1,downsample_factor))\n",
    "        if target == 1: #enmo의 경우\n",
    "\n",
    "            feat = np.sum(feat, 1)\n",
    "\n",
    "            feat = 100 / (feat + 1) #스케일링 후 역수를 취해 작은 값의 비중을 크게 함\n",
    "\n",
    "            return np.dstack([feat])[0]\n",
    "        else:\n",
    "            feat_mean = np.mean(feat,1)\n",
    "            feat_std = np.std(feat,1)\n",
    "            feat_median = np.median(feat,1)\n",
    "            feat_max = np.max(feat,1)\n",
    "            feat_min = np.min(feat,1)\n",
    "            return np.dstack([feat_mean,feat_std,feat_median,feat_max,feat_min])[0]\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = pd.read_csv(f\"/kaggle/working/{index}.csv\")\n",
    "        X = X[['anglez','enmo']].values.astype(np.float32)\n",
    "        X = np.concatenate([self.downsample_seq_generate_features(X[:,i],i,12) for i in range(X.shape[1])],-1)\n",
    "        X = torch.from_numpy(X).to(torch.float32)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ccd188d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T23:33:58.181519Z",
     "iopub.status.busy": "2023-12-05T23:33:58.181060Z",
     "iopub.status.idle": "2023-12-05T23:33:58.204743Z",
     "shell.execute_reply": "2023-12-05T23:33:58.203597Z"
    },
    "papermill": {
     "duration": 0.030284,
     "end_time": "2023-12-05T23:33:58.207015",
     "exception": false,
     "start_time": "2023-12-05T23:33:58.176731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i, viz_id in enumerate(test_series.series_id.unique()):\n",
    "    file_name = f\"/kaggle/working/{i}.csv\"\n",
    "    d = test_series.loc[(test_series.series_id==viz_id)].copy().reset_index()\n",
    "    d.to_csv(file_name, index=False)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dac62e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T23:33:58.216843Z",
     "iopub.status.busy": "2023-12-05T23:33:58.216521Z",
     "iopub.status.idle": "2023-12-05T23:34:00.232040Z",
     "shell.execute_reply": "2023-12-05T23:34:00.231228Z"
    },
    "papermill": {
     "duration": 2.023048,
     "end_time": "2023-12-05T23:34:00.234390",
     "exception": false,
     "start_time": "2023-12-05T23:33:58.211342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_ds = SleepDataset(test_series.series_id.unique())\n",
    "del test_series\n",
    "gc.collect()\n",
    "max_chunk_size = 24 * 60 * 12\n",
    "min_interval = 30\n",
    "model = Transformer(input_size=6,hidden_size=64,out_size=2,n_layers=5).to(device).eval()\n",
    "model.load_state_dict(torch.load(f'/kaggle/input/model/tr-model_best.pth',map_location=device))\n",
    "submission = pd.DataFrame()\n",
    "for i in range(len(ids)):\n",
    "    batch = test_ds[i]\n",
    "    data = pd.read_csv(f\"/kaggle/working/{i}.csv\")\n",
    "    data_length = len(batch)\n",
    "    series_id = ids[i]\n",
    "    for chunk_start in range(0, data_length, max_chunk_size):\n",
    "        chunk_end = min(chunk_start + max_chunk_size, data_length)\n",
    "        pred = np.array([], dtype=np.float16).reshape(0, 2)\n",
    "        for cchunk in range(chunk_start, chunk_end, max_chunk_size//12):\n",
    "            with torch.no_grad():\n",
    "                chunk = batch[cchunk:min(chunk_end, cchunk+max_chunk_size//12)].clone().to(device)\n",
    "                pred_ = model(chunk).half().cpu().numpy()[:, -1, :]\n",
    "            pred = np.concatenate((pred, pred_), axis=0)\n",
    "            del pred_\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        del chunk\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        days = len(pred) / (17280 / 12)\n",
    "        scores0, scores1 = np.zeros(len(pred), dtype=np.float16), np.zeros(len(pred), dtype=np.float16)\n",
    "        for index in range(len(pred)):\n",
    "            if pred[index, 0] == max(pred[max(0, index - min_interval):min(len(pred), index + min_interval), 0]):\n",
    "                scores0[index] = max(pred[max(0, index - min_interval):min(len(pred), index + min_interval), 0])\n",
    "            if pred[index, 1] == max(pred[max(0, index - min_interval):min(len(pred), index + min_interval), 1]):\n",
    "                scores1[index] = max(pred[max(0, index - min_interval):min(len(pred), index + min_interval), 1])\n",
    "        del pred\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        candidates_onset = chunk_start + np.argsort(scores0)[-max(1, round(days)):]\n",
    "        candidates_wakeup = chunk_start + np.argsort(scores1)[-max(1, round(days)):]\n",
    "        onset = data[['step']].iloc[np.clip(candidates_onset * 12, 0, len(batch) - 1)].astype(np.int32)\n",
    "        onset['event'] = 'onset'\n",
    "        onset['series_id'] = series_id\n",
    "        onset['score'] = scores0[candidates_onset]\n",
    "        wakeup = data[['step']].iloc[np.clip(candidates_wakeup * 12, 0, len(batch) - 1)].astype(np.int32)\n",
    "        wakeup['event'] = 'wakeup'\n",
    "        wakeup['series_id'] = series_id\n",
    "        wakeup['score'] = scores1[candidates_wakeup]\n",
    "        submission = pd.concat([submission, onset, wakeup], axis=0)\n",
    "        del onset, wakeup, candidates_onset, candidates_wakeup\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "submission = submission.sort_values(['series_id', 'step']).reset_index(drop=True)\n",
    "submission['row_id'] = submission.index.astype(int) \n",
    "submission['score'] = submission['score'].fillna(submission['score'].mean())\n",
    "submission = submission[['row_id','series_id','step','event','score']]\n",
    "submission.to_csv('/kaggle/working/submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20ac2b60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-05T23:34:00.243889Z",
     "iopub.status.busy": "2023-12-05T23:34:00.243441Z",
     "iopub.status.idle": "2023-12-05T23:34:00.258425Z",
     "shell.execute_reply": "2023-12-05T23:34:00.257554Z"
    },
    "papermill": {
     "duration": 0.02195,
     "end_time": "2023-12-05T23:34:00.260475",
     "exception": false,
     "start_time": "2023-12-05T23:34:00.238525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>step</th>\n",
       "      <th>event</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>12</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.453613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>12</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.214355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>03d92c9f6f8a</td>\n",
       "      <td>12</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.453125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>03d92c9f6f8a</td>\n",
       "      <td>12</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.213379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0402a003dae9</td>\n",
       "      <td>12</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.548340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0402a003dae9</td>\n",
       "      <td>12</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.337646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id     series_id  step   event     score\n",
       "0       0  038441c925bb    12   onset  0.453613\n",
       "1       1  038441c925bb    12  wakeup  0.214355\n",
       "2       2  03d92c9f6f8a    12   onset  0.453125\n",
       "3       3  03d92c9f6f8a    12  wakeup  0.213379\n",
       "4       4  0402a003dae9    12   onset  0.548340\n",
       "5       5  0402a003dae9    12  wakeup  0.337646"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 6589269,
     "sourceId": 53666,
     "sourceType": "competition"
    },
    {
     "datasetId": 3942612,
     "sourceId": 7113852,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30559,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 15.719269,
   "end_time": "2023-12-05T23:34:02.463329",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-05T23:33:46.744060",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
